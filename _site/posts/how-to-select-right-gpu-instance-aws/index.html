<!DOCTYPE html>









<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en"
  
>

  <!--
  The Head
-->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  

    

    

  

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.1" />
<meta property="og:title" content="How to Select the Right GPU Instance for Your Team on AWS?" />
<meta name="author" content="Raahul Dutta" />
<meta property="og:locale" content="en" />
<meta name="description" content="Imagination is the exaggeration of the data you have in your brain. I want to train a diffusion model to compose a piece of music on a lovely evening in Amsterdam. But I require an AWS GPU instance to achieve this. We, the machine learning engineers, are always baffled about the optimal GPU instance on GPU. I completed a short study on this, and the outcome is that:" />
<meta property="og:description" content="Imagination is the exaggeration of the data you have in your brain. I want to train a diffusion model to compose a piece of music on a lovely evening in Amsterdam. But I require an AWS GPU instance to achieve this. We, the machine learning engineers, are always baffled about the optimal GPU instance on GPU. I completed a short study on this, and the outcome is that:" />
<link rel="canonical" href="http://localhost:4000/posts/how-to-select-right-gpu-instance-aws/" />
<meta property="og:url" content="http://localhost:4000/posts/how-to-select-right-gpu-instance-aws/" />
<meta property="og:site_name" content="Musings on AI" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-11-20T00:32:00+01:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="How to Select the Right GPU Instance for Your Team on AWS?" />
<meta name="twitter:site" content="@raahul_rahl" />
<meta name="twitter:creator" content="@raahul_rahl" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Raahul Dutta","url":"https://www.linkedin.com/in/raahuldutta/"},"dateModified":"2022-11-21T01:34:09+01:00","datePublished":"2022-11-20T00:32:00+01:00","description":"Imagination is the exaggeration of the data you have in your brain. I want to train a diffusion model to compose a piece of music on a lovely evening in Amsterdam. But I require an AWS GPU instance to achieve this. We, the machine learning engineers, are always baffled about the optimal GPU instance on GPU. I completed a short study on this, and the outcome is that:","headline":"How to Select the Right GPU Instance for Your Team on AWS?","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/how-to-select-right-gpu-instance-aws/"},"url":"http://localhost:4000/posts/how-to-select-right-gpu-instance-aws/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>How to Select the Right GPU Instance for Your Team on AWS? | Musings on AI
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="Musings on AI">
<meta name="application-name" content="Musings on AI">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  

    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">

  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/style.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>

  
    <!--
  Switch the mode between dark and light.
-->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() { return "mode"; }
    static get MODE_ATTR() { return "data-mode"; }
    static get DARK_MODE() { return "dark"; }
    static get LIGHT_MODE() { return "light"; }
    static get ID() { return "mode-toggle"; }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener("change", () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }

          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();

      });

    } /* constructor() */

    get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); }

    get isSysDarkPrefer() { return this.sysDarkPrefers.matches; }

    get isDarkMode() { return this.mode === ModeToggle.DARK_MODE; }

    get isLightMode() { return this.mode === ModeToggle.LIGHT_MODE; }

    get hasMode() { return this.mode != null; }

    get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode
        || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      $('html').attr(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      $('html').removeAttr(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage({
        direction: ModeToggle.ID,
        message: this.modeStatus
      }, "*");
    }

  } /* ModeToggle */

  const toggle = new ModeToggle();

  function flipMode() {
    if (toggle.hasMode) {
      if (toggle.isSysDarkPrefer) {
        if (toggle.isLightMode) {
          toggle.clearMode();
        } else {
          toggle.setLight();
        }

      } else {
        if (toggle.isDarkMode) {
          toggle.clearMode();
        } else {
          toggle.setDark();
        }
      }

    } else {
      if (toggle.isSysDarkPrefer) {
        toggle.setLight();
      } else {
        toggle.setDark();
      }
    }

    toggle.notify();

  } /* flipMode() */

</script>

  
</head>


  <body data-spy="scroll" data-target="#toc" data-topbar-visible="true">

    <!--
  The Side Bar
-->

<div id="sidebar" class="d-flex flex-column align-items-end">
  <div class="profile-wrapper text-center">
    <div id="avatar">
      <a href="/" class="mx-auto">
        
          
          <img src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/raahul.png" alt="avatar" onerror="this.style.display='none'">
        
      </a>
    </div>

    <div class="site-title">
      <a href="/">Musings on AI</a>
    </div>
    <div class="site-subtitle font-italic">This is Musings on AI, a newsletter about I post weekly newsletters on the hottest Musings on Artificial Intelligence.</div>

  </div><!-- .profile-wrapper -->

  <ul class="w-100">

    <!-- home -->
    <li class="nav-item">
      <a href="/" class="nav-link">
        <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i>
        <span>HOME</span>
      </a>
    </li>
    <!-- the real tabs -->
    
    <li class="nav-item">
      <a href="/archives/" class="nav-link">
        <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ARCHIVES</span>
      </a>
    </li> <!-- .nav-item -->
    
    <li class="nav-item">
      <a href="/about/" class="nav-link">
        <i class="fa-fw fas fa-info-circle ml-xl-3 mr-xl-3 unloaded"></i>
        

        <span>ABOUT</span>
      </a>
    </li> <!-- .nav-item -->
    

  </ul> <!-- ul.nav.flex-column -->

  <div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center align-items-center">

    
      <button class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
      <a href="https://github.com/raahuldutta" aria-label="github"
        target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
      

    
      

      
      <a href="https://twitter.com/raahul_rahl" aria-label="twitter"
        target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
      

    
      

      
      <a href="
          javascript:location.href = 'mailto:' + ['dutta.raahul','gmail.com'].join('@')" aria-label="email"
        >
        <i class="fas fa-envelope"></i>
      </a>
      

    
      

      
      <a href="" aria-label="mastodon"
        target="_blank" rel="noopener">
        <i class="fab fa-mastodon"></i>
      </a>
      

    
      

      
      <a href="" aria-label="linkedin"
        target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
      

    

  </div> <!-- .sidebar-bottom -->

</div><!-- #sidebar -->


    <!--
  The Top Bar
-->

<div id="topbar-wrapper">
  <div id="topbar" class="container d-flex align-items-center justify-content-between h-100 pl-3 pr-3 pl-md-4 pr-md-4">
    <span id="breadcrumb">

    

    

      

        
          <span>
            <a href="/">
              Home
            </a>
          </span>

        

      

        

      

        

          
            <span>How to Select the Right GPU Instance for Your Team on AWS?</span>
          

        

      

    

    </span><!-- endof #breadcrumb -->

    <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i>

    <div id="topbar-title">
      Post
    </div>

    <i id="search-trigger" class="fas fa-search fa-fw"></i>
    <span id="search-wrapper" class="align-items-center">
      <i class="fas fa-search fa-fw"></i>
      <input class="form-control" id="search-input" type="search"
        aria-label="search" autocomplete="off" placeholder="Search...">
    </span>
    <span id="search-cancel" >Cancel</span>
  </div>

</div>


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div id="main" class="container pl-xl-4 pr-xl-4">
        





<div class="row">

  <!-- core -->
  <div id="core-wrapper" class="col-12 col-lg-11 col-xl-9 pr-xl-4">
    <div class="post pl-1 pr-1 pl-md-2 pr-md-2">

    

    
      
      
        <!--
  Refactor the HTML structure.
-->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->


<!-- images -->




  
  

  
    
      
      
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  
    

    
    
    

    
    

    
    
    

    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
    
      
      

      
      

      

      
        

    
      

        <!-- Add CDN URL -->
        

        <!-- Add image path -->
        

        
        

      

      <!-- lazy-load images <https://github.com/ApoorvSaxena/lozad.js#usage> -->

      

    

    <!-- Add SVG placehoder to prevent layout reflow -->

    

    <!-- Bypass the HTML-proofer test -->
    

    

  

  



<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    
      

      
      

      
      
      

      

    

    

  

  
  

  

  
  

  




<!-- Wrap prompt element of blockquote with the <div> tag -->







  
  

  

    
      
      

    

    
    

    
    
    

    
      
        
        

    

    
    

    

  

    

    
    

    
    
    

    
      
        
        

    

    
    

    

  

  



<!-- return -->

<h1 data-toc-skip>How to Select the Right GPU Instance for Your Team on AWS?</h1>

<div class="post-meta text-muted">
    <!-- published date -->
    <span>
      Posted
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1668900720"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Nov 20, 2022
</em>

    </span>

    <!-- lastmod date -->
    
    <span>
      Updated
      <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class=""
    data-ts="1668990849"
    data-df="ll"
    data-toggle="tooltip" data-placement="bottom">
  Nov 21, 2022
</em>

    </span>
    

  

  <div class="d-flex justify-content-between">
    <!-- author(s) -->
    <span>
      

      By

      <em>
      
        
          <a href="https://www.linkedin.com/in/raahuldutta/">Raahul Dutta</a>
          
        
      
      </em>
    </span>

    <div>
      <!-- page views -->
      

      <!-- read time -->
      <!--
  Calculate the post's reading time, and display the word count in tooltip
 -->



<!-- words per minute  -->










<!-- return element -->
<span class="readtime" data-toggle="tooltip" data-placement="bottom"
  title="1367 words">
  <em>7 min</em> read</span>

    </div>

  </div> <!-- .d-flex -->

</div> <!-- .post-meta -->

<div class="post-content">
  <p>Imagination is the exaggeration of the data you have in your brain. I want to train a diffusion model to compose a piece of music on a lovely evening in Amsterdam. But I require an AWS GPU instance to achieve this. We, the machine learning engineers, are always baffled about the optimal GPU instance on GPU. I completed a short study on this, and the outcome is that:</p>

<h2 id="the-decision-tree-to-decide-gpu"><span class="mr-2">The Decision Tree to Decide GPU</span><a href="#the-decision-tree-to-decide-gpu" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/decision_tree.jpeg" alt="aws" width="616" height="557" data-proofer-ignore></p>

<p>If you are doing HPC (High Performance Job) like Drug Discovery or High Precision Job, then we suggest following the P (historically called Performance-Heavy) Instance Family. Else we recommend following the G (historically called Graphics-Heavy) Instance Family. I am providing the cost chart for the noted GPU instances.</p>

<h2 id="p3-and-p4-instances-cost"><span class="mr-2">P3 and P4 Instances Cost</span><a href="#p3-and-p4-instances-cost" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/p3_p4.jpeg" alt="aws" width="616" height="557" data-proofer-ignore></p>

<h2 id="g4-and-g5-instances-cost"><span class="mr-2">G4 and G5 Instances Cost</span><a href="#g4-and-g5-instances-cost" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/g4_g5.jpeg" alt="aws" width="616" height="557" data-proofer-ignore></p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/dalle.png" alt="aws" width="616" height="557" data-proofer-ignore></p>

<p>This image is not related to the GPU instance - I got the picture from Dall-E, it’s not an actual view. The concept was generated with the diffusion model.</p>

<h2 id="always-dont-select-gpu-on-the-price-ground"><span class="mr-2">Always Don’t Select GPU on the Price Ground</span><a href="#always-dont-select-gpu-on-the-price-ground" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p>Please don’t select the GPU always as per the pricing basis. We executed a little experiment- We trained a Scibert Transformer model with 100K data points.
The result on a <code class="language-plaintext highlighter-rouge">g4dn.2xlarge</code> machine:</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/g4dn_price.png" alt="aws" width="616" height="557" data-proofer-ignore></p>

<blockquote class="prompt-info"><div>
  <p>The cost is : (0.752 * 311.25) / 3600  = $0.06</p>
</div></blockquote>

<p>We executed on a <code class="language-plaintext highlighter-rouge">g5.xlarge</code> machine too. The result is on the same configuration :</p>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/g5_price.png" alt="aws" width="616" height="557" data-proofer-ignore></p>

<blockquote class="prompt-info"><div>
  <p>The cost is : (1.006 * 197.31) / 3600  = $0.05</p>
</div></blockquote>

<h3 id="so-if-we-use-a-g5xlarge-machine-then-we-can-save-20-of-our-budget"><span class="mr-2">So if we use a g5.xlarge machine then we can save 20% of our budget.</span><a href="#so-if-we-use-a-g5xlarge-machine-then-we-can-save-20-of-our-budget" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>And other benefits of a g5 family over a g4 family are:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">NVIDIA Ampere Architecture</code> is modern architecture, it supports all the precision formats.</li>
  <li>We should follow the <code class="language-plaintext highlighter-rouge">Mixed Precision Training</code> in Pytoch based project.There are different types of floating datatypes - <code class="language-plaintext highlighter-rouge">FP32</code>, <code class="language-plaintext highlighter-rouge">FP16</code>, <code class="language-plaintext highlighter-rouge">TF32</code>, <code class="language-plaintext highlighter-rouge">BF16</code></li>
</ul>

<p><img src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 616 557'%3E%3C/svg%3E" data-src="https://raw.githubusercontent.com/raahuldutta/musingsonai_img/master/posts/202201119/vidia.png" alt="aws" width="616" height="557" data-proofer-ignore></p>

<p>source: NVIDIA Blog</p>

<p>We executed the apple-to-apple comparison with <code class="language-plaintext highlighter-rouge">fp16</code> datatype because <code class="language-plaintext highlighter-rouge">tf32</code> and <code class="language-plaintext highlighter-rouge">bf16</code> need the <code class="language-plaintext highlighter-rouge">Ampere Architecture</code> which is available under <code class="language-plaintext highlighter-rouge">g5 instances</code> family.</p>

<h2 id="ps--what-is-tf32-and-bf16"><span class="mr-2">PS : What is TF32 and BF16?</span><a href="#ps--what-is-tf32-and-bf16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<h3 id="bf16"><span class="mr-2">BF16</span><a href="#bf16" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre>If you have access to a Ampere or newer hardware you can use bf16 for your training and evaluation. While bf16 has a worse precision than fp16, it has a much much bigger dynamic range. Therefore, if in the past you were experiencing overflow issues while training the model, bf16 will prevent this from happening most of the time. Remember that in fp16 the biggest number you can have is `65535` and any number above that will overflow. A bf16 number can be as large as `3.39e+38` (!) which is about the same as fp32 - because both have 8-bits used for the numerical range.
</pre></td></tr></tbody></table></code></div></div>

<h3 id="tf32"><span class="mr-2">TF32</span><a href="#tf32" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<div class="language-plaintext highlighter-rouge"><div class="code-header">
        <span data-label-text="Plaintext"><i class="fas fa-code small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre></td><td class="rouge-code"><pre>The Ampere hardware uses a magical data type called tf32. It has the same numerical range as fp32 (8-bits), but instead of 23 bits precision it has only 10 bits (same as fp16) and uses only 19 bits in total.
It’s magical in the sense that you can use the normal fp32 training and/or inference code and by enabling tf32 support you can get up to 3x throughput improvement.
When this is done CUDA will automatically switch to using tf32 instead of fp32 where it’s possible. This, of course, assumes that the used GPU is from the Ampere series.
Like all cases with reduced precision this may or may not be satisfactory for your needs, so you have to experiment and see. According to NVIDIA research the majority of machine learning training shouldn’t be impacted and showed the same perplexity and convergence as the fp32 training.
</pre></td></tr></tbody></table></code></div></div>

<h2 id="and-i-found-the-detailed-aws-gpu-instance-details-for-further-read"><span class="mr-2">And I found the detailed AWS GPU Instance details for further read</span><a href="#and-i-found-the-detailed-aws-gpu-instance-details-for-further-read" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<div class="table-wrapper"><table>
  <thead>
    <tr>
      <th>Architecture</th>
      <th>NVIDIA GPU</th>
      <th>Instance type</th>
      <th>Instance name</th>
      <th>Number of GPUs</th>
      <th>GPU Memory (per GPU)</th>
      <th>GPU Interconnect (NVLink / PCIe)</th>
      <th>Thermal<br />Design Power (TDP) from nvidia-smi</th>
      <th>Tensor Cores (mixed-precision)</th>
      <th>Precision Support</th>
      <th>CPU Type</th>
      <th>Nitro based</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Ampere</td>
      <td>A100</td>
      <td>P4</td>
      <td>p4d.24xlarge</td>
      <td>8</td>
      <td>40 GB</td>
      <td>NVLink gen 3 (600 GB/s)</td>
      <td>400W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.xlarge</td>
      <td>1</td>
      <td>24 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.2xlarge</td>
      <td>1</td>
      <td>24 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.4xlarge</td>
      <td>1</td>
      <td>24 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.8xlarge</td>
      <td>1</td>
      <td>24 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.16xlarge</td>
      <td>1</td>
      <td>24 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.12xlarge</td>
      <td>4</td>
      <td>24 GB</td>
      <td>PCIe</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.24xlarge</td>
      <td>4</td>
      <td>24 GB</td>
      <td>PCIe</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Ampere</td>
      <td>A10G</td>
      <td>G5</td>
      <td>g5.48xlarge</td>
      <td>8</td>
      <td>24 GB</td>
      <td>PCIe</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 3)</td>
      <td>FP64, FP32, FP16, INT8, BF16, TF32</td>
      <td>AMD EPYC</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.2xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.4xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.8xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.16xlarge</td>
      <td>2</td>
      <td>16 GB</td>
      <td>PCIe</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4G</td>
      <td>G5</td>
      <td>g5g.metal</td>
      <td>2</td>
      <td>16 GB</td>
      <td>PCIe</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>AWS Graviton2</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.2xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.4xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.8xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.16xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.12xlarge</td>
      <td>4</td>
      <td>16 GB</td>
      <td>PCIe</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Turing</td>
      <td>T4</td>
      <td>G4</td>
      <td>g4dn.metal</td>
      <td>8</td>
      <td>16 GB</td>
      <td>PCIe</td>
      <td>70W</td>
      <td>Tensor Cores (Gen 2)</td>
      <td>FP32, FP16, INT8</td>
      <td>Intel Xeon Scalable (Cascade Lake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Volta</td>
      <td>V100</td>
      <td>P3</td>
      <td>p3.2xlarge</td>
      <td>1</td>
      <td>16 GB</td>
      <td>NA (single GPU)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 1)</td>
      <td>FP64, FP32, FP16</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Volta</td>
      <td>V100</td>
      <td>P3</td>
      <td>p3.8xlarge</td>
      <td>4</td>
      <td>16 GB</td>
      <td>NVLink gen 2 (300 GB/s)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 1)</td>
      <td>FP64, FP32, FP16</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Volta</td>
      <td>V100</td>
      <td>P3</td>
      <td>p3.16xlarge</td>
      <td>8</td>
      <td>16 GB</td>
      <td>NVLink gen 2 (300 GB/s)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 1)</td>
      <td>FP64, FP32, FP16</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Volta</td>
      <td>V100*</td>
      <td>P3</td>
      <td>p3dn.24xlarge</td>
      <td>8</td>
      <td>32 GB</td>
      <td>NVLink gen 2 (300 GB/s)</td>
      <td>300W</td>
      <td>Tensor Cores (Gen 1)</td>
      <td>FP64, FP32, FP16</td>
      <td>Intel Xeon (Skylake)</td>
      <td>Yes</td>
    </tr>
    <tr>
      <td>Kepler</td>
      <td>K80</td>
      <td>P2</td>
      <td>p2.xlarge</td>
      <td>1</td>
      <td>12 GB</td>
      <td>NA (single GPU)</td>
      <td>149W</td>
      <td>No</td>
      <td>FP64, FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Kepler</td>
      <td>K80</td>
      <td>P2</td>
      <td>p2.8xlarge</td>
      <td>8</td>
      <td>12 GB</td>
      <td>PCIe</td>
      <td>149W</td>
      <td>No</td>
      <td>FP64, FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Kepler</td>
      <td>K80</td>
      <td>P2</td>
      <td>p2.16xlarge</td>
      <td>16</td>
      <td>12 GB</td>
      <td>PCIe</td>
      <td>149W</td>
      <td>No</td>
      <td>FP64, FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Maxwell</td>
      <td>M60</td>
      <td>G3</td>
      <td>g3s.xlarge</td>
      <td>1</td>
      <td>8 GB</td>
      <td>PCIe</td>
      <td>150W</td>
      <td>No</td>
      <td>FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Maxwell</td>
      <td>M60</td>
      <td>G3</td>
      <td>g3.4xlarge</td>
      <td>1</td>
      <td>8 GB</td>
      <td>PCIe</td>
      <td>150W</td>
      <td>No</td>
      <td>FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Maxwell</td>
      <td>M60</td>
      <td>G3</td>
      <td>g3.8xlarge</td>
      <td>2</td>
      <td>8 GB</td>
      <td>PCIe</td>
      <td>150W</td>
      <td>No</td>
      <td>FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
    <tr>
      <td>Maxwell</td>
      <td>M60</td>
      <td>G3</td>
      <td>g3.16xlarge</td>
      <td>4</td>
      <td>8 GB</td>
      <td>PCIe</td>
      <td>150W</td>
      <td>No</td>
      <td>FP32</td>
      <td>Intel Xeon (Broadwell)</td>
      <td>No</td>
    </tr>
  </tbody>
</table></div>

<h2 id="reference"><span class="mr-2">Reference</span><a href="#reference" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<ul>
  <li><a href="https://towardsdatascience.com/choosing-the-right-gpu-for-deep-learning-on-aws-d69c157d8c86">Choosing the right GPU for deep learning on AWS</a></li>
  <li><a href="https://youtu.be/4bVrIbgGWEA">AWS re:Invent 2021 - How to select Amazon EC2 GPU instances for deep learning (sponsored by NVIDIA)</a></li>
</ul>


</div>

<div class="post-tail-wrapper text-muted">

  <!-- categories -->
  

  <!-- tags -->
  

  <div class="post-tail-bottom
    d-flex justify-content-between align-items-center mt-3 pt-5 pb-2">
    <div class="license-wrapper">

      

        

        This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.

      
    </div>

    <!--
 Post sharing snippet
-->

<div class="share-wrapper">
  <span class="share-label text-muted mr-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
        <a href="https://twitter.com/intent/tweet?text=How+to+Select+the+Right+GPU+Instance+for+Your+Team+on+AWS%3F+-+Musings+on+AI&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fhow-to-select-right-gpu-instance-aws%2F" data-toggle="tooltip" data-placement="top"
          title="Twitter" target="_blank" rel="noopener" aria-label="Twitter">
          <i class="fa-fw fab fa-twitter"></i>
        </a>
    
      
        <a href="https://www.facebook.com/sharer/sharer.php?title=How+to+Select+the+Right+GPU+Instance+for+Your+Team+on+AWS%3F+-+Musings+on+AI&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fhow-to-select-right-gpu-instance-aws%2F" data-toggle="tooltip" data-placement="top"
          title="Facebook" target="_blank" rel="noopener" aria-label="Facebook">
          <i class="fa-fw fab fa-facebook-square"></i>
        </a>
    
      
        <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fhow-to-select-right-gpu-instance-aws%2F&text=How+to+Select+the+Right+GPU+Instance+for+Your+Team+on+AWS%3F+-+Musings+on+AI" data-toggle="tooltip" data-placement="top"
          title="Telegram" target="_blank" rel="noopener" aria-label="Telegram">
          <i class="fa-fw fab fa-telegram"></i>
        </a>
    
      
        <a href="https://www.linkedin.com/sharing/share-offsite/?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fhow-to-select-right-gpu-instance-aws%2F" data-toggle="tooltip" data-placement="top"
          title="Linkedin" target="_blank" rel="noopener" aria-label="Linkedin">
          <i class="fa-fw fab fa-linkedin"></i>
        </a>
    

    <i id="copy-link" class="fa-fw fas fa-link small"
        data-toggle="tooltip" data-placement="top"
        title="Copy link"
        data-title-succeed="Link copied successfully!">
    </i>

  </span>
</div>


  </div><!-- .post-tail-bottom -->

</div><!-- div.post-tail-wrapper -->


      
    
    

    </div>
  </div> <!-- #core-wrapper -->

  <!-- panel -->
  <div id="panel-wrapper" class="col-xl-3 pl-2 text-muted">

    <div class="access">
      















  <div id="access-lastmod" class="post">
    <div class="panel-heading"></div>
    <ul class="post-content pl-0 pb-1 ml-1 mt-2">
      
        
        
        
      <li><a href="/posts/how-to-select-right-gpu-instance-aws/">How to Select the Right GPU Instance for Your Team on AWS?</a></li>
      
    </ul>
  </div> <!-- #access-lastmod -->



      


















    </div>

    
      
      



<!-- BS-toc.js will be loaded at medium priority -->
<script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script>

<div id="toc-wrapper" class="pl-0 pr-4 mb-5">
  <div class="panel-heading pl-3 pt-2 mb-2">Contents</div>
  <nav id="toc" data-toggle="toc"></nav>
</div>


    
  </div>

</div>

<!-- tail -->

<div class="row">
  <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 pl-3 pr-3 pr-xl-4 mt-5">
    
      
      <!--
 Recommend the other 3 posts according to the tags and categories of the current post,
 if the number is not enough, use the other latest posts to supplement.
-->

<!-- The total size of related posts  -->


<!-- An random integer that bigger than 0  -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy}  -->








  

  

  

  

  

  


  

  
    






<!-- Fill with the other newlest posts  -->



  
    
    
      
      
        
        
        
      
    
  
    
    
  



  <div id="related-posts" class="mb-2 mb-sm-4">
    <h3 class="pt-2 mb-4 ml-1"
      data-toc-skip>Further Reading</h3>
    <div class="card-deck mb-4">
    
      
      
      <div class="card">
        <a href="/posts/model-deploymet-kserve/">
          <div class="card-body">
            <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->





<em class="small"
    data-ts="1668900720"
    data-df="ll"
    >
  Nov 20, 2022
</em>

            <h3 class="pt-0 mt-1 mb-3" data-toc-skip>Model Deployment with KServe and KServe Features</h3>
            <div class="text-muted small">
              <p>
                





                On a Friday Evening, Mid-September 2019 - Coworkers were leaving the office. The evening was welcoming a bright night. And I was working to deploy the LSTM models on production. I knew - “don’t dep...
              </p>
            </div>
          </div>
        </a>
      </div>
    
    </div> <!-- .card-deck -->
  </div> <!-- #related-posts -->


    
      
      <!--
  Navigation buttons at the bottom of the post.
-->

<div class="post-navigation d-flex justify-content-between">
  
  <div class="btn btn-outline-primary disabled"
    prompt="Older">
    <p>-</p>
  </div>
  

  
  <a href="/posts/model-deploymet-kserve/" class="btn btn-outline-primary"
    prompt="Newer">
    <p>Model Deployment with KServe and KServe Features</p>
  </a>
  

</div>

    
      
      <!--  The comments switcher -->


    
  </div>
</div>


      </div>

      <!--
  The Search results
-->
<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-12 col-sm-11 post-content">
    <div id="search-hints">
      


















    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>


    </div> <!-- #main-wrapper -->

    <!-- The Footer -->

<footer>
  <div class="container pl-lg-4 pr-lg-4">
    <div class="d-flex justify-content-between align-items-center text-muted ml-md-3 mr-md-3">
      <div class="footer-left">
        <p class="mb-0">
          © 2022
          <a href="https://twitter.com/raahul_rahl">Raahul Dutta</a>.
          
          <span data-toggle="tooltip" data-placement="top"
            title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span>
          
        </p>
      </div>

      <div class="footer-right">
        <p class="mb-0">

          

          

          Powered by 
          <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
           with 
          <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a>
           theme.
        </p>
      </div>
    </div>
  </div>
</footer>


    

    <div id="mask"></div>

    <a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button">
      <i class="fas fa-angle-up"></i>
    </a>

    
      <div id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true"
        data-animation="true" data-autohide="false">
        <div class="toast-header">
          <button type="button" class="ml-2 ml-auto close" data-dismiss="toast" aria-label="Close">
            <span aria-hidden="true">&times;</span>
          </button>
        </div>
        <div class="toast-body text-center pt-0">
          <p class="pl-2 pr-2 mb-3">A new version of content is available.</p>
          <button type="button" class="btn btn-primary" aria-label="Update">
            Update
          </button>
        </div>
      </div>
    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js"></script>

<script>
SimpleJekyllSearch({
  searchInput: document.getElementById('search-input'),
  resultsContainer: document.getElementById('search-results'),
  json: '/assets/js/data/search.json',
  searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0">  <a href="{url}">{title}</a>  <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">    {categories}    {tags}  </div>  <p>{snippet}</p></div>',
  noResultsText: '<p class="mt-5">Oops! No results found.</p>',
  templateMiddleware: function(prop, value, template) {
    if (prop === 'categories') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
      }
    }

    if (prop === 'tags') {
      if (value === '') {
        return `${value}`;
      } else {
        return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
      }
    }
  }
});
</script>


    <!--
  JS selector for site.
-->

<!-- layout specified -->


  



  <!-- image lazy-loading & popup & clipboard -->
  

  







  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/magnific-popup@1/dist/jquery.magnific-popup.min.js,npm/lozad/dist/lozad.min.js,npm/clipboard@2/dist/clipboard.min.js"></script>







  

  

  







  
    

    

  



  
    

    

  



  
    

    

  



  
    

    

  




  <script src="https://cdn.jsdelivr.net/combine/npm/dayjs@1/dayjs.min.js,npm/dayjs@1/locale/en.min.js,npm/dayjs@1/plugin/relativeTime.min.js,npm/dayjs@1/plugin/localizedFormat.min.js"></script>








<script defer src="/assets/js/dist/post.min.js"></script>



<!-- commons -->

<script src="https://cdn.jsdelivr.net/npm/bootstrap@4/dist/js/bootstrap.bundle.min.js"></script>




  </body>

</html>
